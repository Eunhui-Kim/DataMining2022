{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UTF-8\n",
      "    02 성별  06_나이_반올림  001_오른쪽어깨경사각  002_왼쪽어깨경사각  003_키 005_목뒤높이  017_샅높이  \\\n",
      "450     남         44          21.0         17.0  1,713    1,454    790.0   \n",
      "452     남         23          24.0         24.0  1,714    1,450    783.0   \n",
      "453     남         23          23.0         23.0  1,731    1,477    737.0   \n",
      "454     남         23          25.0         23.0  1,730    1,468    770.0   \n",
      "462     남         24          23.0         20.0  1,685    1,442    793.0   \n",
      "\n",
      "     031_몸무게  037_목둘레  038_목밑둘레  ... 064_팔길이 065_팔안쪽길이 069_다리가쪽길이 111_머리둘레  \\\n",
      "450     78.2    407.0     458.0  ...   584.0     430.0      1,036    572.0   \n",
      "452     70.3    364.0     418.0  ...   601.0     487.0      1,034    587.0   \n",
      "453     74.7    380.0     439.0  ...   630.0     504.0      1,067    583.0   \n",
      "454     95.0    422.0     461.0  ...   612.0     479.0      1,038    609.0   \n",
      "462     70.0    374.0     437.0  ...   597.0     463.0      1,022    558.0   \n",
      "\n",
      "    121_넙다리둘레 122_넙다리중간둘레 123_무릎둘레  125_장딴지둘레  130_위팔둘레  131_팔꿈치둘레  \n",
      "450     601.0       553.0    393.0      395.0     329.0      286.0  \n",
      "452     593.0       550.0    379.0      376.0     306.0      264.0  \n",
      "453     583.0       532.0    386.0      407.0     305.0      292.0  \n",
      "454     667.0       613.0    419.0      435.0     361.0      308.0  \n",
      "462     596.0       531.0    374.0      372.0     303.0      273.0  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "(1789, 30)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# encoding이 \"utf-8\" 한글이 깨지는 경우가 종종 있다. \n",
    "# sizeKorea의 data의 경우 encoding을 \"euc_kr\"로 하였을 경우 문제 해결\n",
    "sizeKoreaData = pd.read_csv(\"data/2015_7_sizeKoreaData.csv\", encoding = \"euc_kr\") \n",
    "print(\"{}\".format(sys.stdout.encoding))\n",
    "#print(\"{}\".format(sizeKoreaData.head()))\n",
    "#print(\"{}\".format(sizeKoreaData.shape))\n",
    "\n",
    "#null data에 대한 전처리\n",
    "sizeKoreaData.isnull().sum()\n",
    "\n",
    "#null data가 있는 row는 삭제\n",
    "sizeKoreaData.dropna(inplace=True)\n",
    "\n",
    "sizeKoreaData.isnull().sum()\n",
    "\n",
    "# 연령 범위가 20~50대 사이인 남성 데이터 만을 추출한 데이터 처리 후 이를 저장\n",
    "sizeKoreaMale2040 = sizeKoreaData[((sizeKoreaData['06_나이_반올림']>=20) & (sizeKoreaData['06_나이_반올림']<50)) & sizeKoreaData['02 성별'].str.contains('남')]\n",
    "print(sizeKoreaMale2040.head())\n",
    "print('{}'.format(sizeKoreaMale2040.shape))\n",
    "sizeKoreaMale2040.to_csv(\"data/sizeKoreaMale2040.csv\", encoding=\"euc-kr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1789, 30)\n",
      "    02 성별  06_나이_반올림  001_오른쪽어깨경사각  002_왼쪽어깨경사각  003_키 005_목뒤높이  017_샅높이  \\\n",
      "450     남         44          21.0         17.0  1,713    1,454    790.0   \n",
      "452     남         23          24.0         24.0  1,714    1,450    783.0   \n",
      "453     남         23          23.0         23.0  1,731    1,477    737.0   \n",
      "454     남         23          25.0         23.0  1,730    1,468    770.0   \n",
      "462     남         24          23.0         20.0  1,685    1,442    793.0   \n",
      "\n",
      "     031_몸무게  037_목둘레  038_목밑둘레  ... 064_팔길이 065_팔안쪽길이 069_다리가쪽길이 111_머리둘레  \\\n",
      "450     78.2    407.0     458.0  ...   584.0     430.0      1,036    572.0   \n",
      "452     70.3    364.0     418.0  ...   601.0     487.0      1,034    587.0   \n",
      "453     74.7    380.0     439.0  ...   630.0     504.0      1,067    583.0   \n",
      "454     95.0    422.0     461.0  ...   612.0     479.0      1,038    609.0   \n",
      "462     70.0    374.0     437.0  ...   597.0     463.0      1,022    558.0   \n",
      "\n",
      "    121_넙다리둘레 122_넙다리중간둘레 123_무릎둘레  125_장딴지둘레  130_위팔둘레  131_팔꿈치둘레  \n",
      "450     601.0       553.0    393.0      395.0     329.0      286.0  \n",
      "452     593.0       550.0    379.0      376.0     306.0      264.0  \n",
      "453     583.0       532.0    386.0      407.0     305.0      292.0  \n",
      "454     667.0       613.0    419.0      435.0     361.0      308.0  \n",
      "462     596.0       531.0    374.0      372.0     303.0      273.0  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "min: 301.0\n",
      "max: 476.0\n",
      "median: 379.0\n"
     ]
    }
   ],
   "source": [
    "print(\"{}\".format(sizeKoreaMale2040.shape))\n",
    "print(\"{}\".format(sizeKoreaMale2040.head()))\n",
    "print(\"min: {}\".format(sizeKoreaMale2040['037_목둘레'].min()))\n",
    "print(\"max: {}\".format(sizeKoreaMale2040['037_목둘레'].max()))\n",
    "print(\"median: {}\".format(sizeKoreaMale2040['037_목둘레'].median()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_data shape :(1789,)\n",
      "31\n",
      "1789,31\n"
     ]
    }
   ],
   "source": [
    "my_data = np.array(sizeKoreaMale2040.to_records())\n",
    "print(\"my_data shape :{}\".format(my_data.shape))\n",
    "print(\"{}\".format(len(my_data[0])))\n",
    "#print(\"{}\".format(len(my_data[0])))\n",
    "(row, column) = my_data.shape[0], len(my_data[0])\n",
    "print(\"{},{}\".format(row, column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301.0\n",
      "1430\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "TX = [x[9] for x in my_data]\n",
    "print(\"{}\".format(min(TX)))\n",
    "n_training = math.floor(row * 0.8)\n",
    "X = TX[1:n_training]\n",
    "print(\"{}\".format(len(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1789, 6)\n",
      "(1430, 6)\n"
     ]
    }
   ],
   "source": [
    "n_training = math.floor(row * 0.8)\n",
    "# 12-젖가슴둘레,13-배꼽수준허리둘레,14 -배둘레, 15-엉덩이둘레, 28-위팔둘레, 7-몸무게\n",
    "TX1 = [float(x[7]) for x in my_data]\n",
    "TX2 = [float(x[12].replace(',','')) for x in my_data]\n",
    "TX3 = [float(x[13].replace(',','')) for x in my_data]\n",
    "TX4 = [float(x[14].replace(',','')) for x in my_data]\n",
    "TX5 = [float(x[15].replace(',','')) for x in my_data]\n",
    "TX6 = [x[28] for x in my_data]\n",
    "TX = np.column_stack((TX1, TX2, TX3, TX4, TX5, TX6))\n",
    "print(\"{}\".format(TX.shape))\n",
    "\n",
    "X = TX[1:n_training, :]\n",
    "print(\"{}\".format(X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301\n"
     ]
    }
   ],
   "source": [
    "v_neck_around_int = [int(x[9]) for x in my_data]\n",
    "print(\"{}\".format(min(v_neck_around_int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_data shape :(1789,)\n",
      "31\n",
      "[407.0, 364.0, 380.0, 422.0, 374.0, 370.0, 354.0, 345.0, 378.0, 378.0, 370.0, 400.0, 363.0, 355.0, 360.0, 373.0, 403.0, 414.0, 400.0, 370.0, 400.0, 400.0, 382.0, 415.0, 376.0, 385.0, 364.0, 360.0, 454.0, 380.0, 345.0, 367.0, 382.0, 357.0, 430.0, 400.0, 395.0, 407.0, 400.0, 362.0, 375.0, 382.0, 368.0, 366.0, 335.0, 353.0, 400.0, 383.0, 350.0, 387.0, 380.0, 400.0, 380.0, 365.0, 374.0, 364.0, 350.0, 365.0, 382.0, 370.0, 388.0, 385.0, 370.0, 365.0, 380.0, 394.0, 414.0, 387.0, 370.0, 380.0, 358.0, 342.0, 417.0, 375.0, 425.0, 384.0, 350.0, 390.0, 343.0, 420.0, 355.0, 365.0, 380.0, 360.0, 364.0, 365.0, 365.0, 375.0, 355.0, 400.0, 401.0, 405.0, 398.0, 360.0, 350.0, 392.0, 382.0, 365.0, 400.0, 393.0, 390.0, 395.0, 375.0, 400.0, 340.0, 370.0, 385.0, 465.0, 430.0, 371.0, 371.0, 366.0, 397.0, 360.0, 382.0, 375.0, 385.0, 410.0, 393.0, 375.0, 365.0, 415.0, 366.0, 430.0, 390.0, 400.0, 360.0, 355.0, 403.0, 430.0, 410.0, 411.0, 350.0, 365.0, 345.0, 420.0, 370.0, 376.0, 365.0, 395.0, 372.0, 415.0, 385.0, 355.0, 360.0, 375.0, 385.0, 352.0, 370.0, 355.0, 350.0, 355.0, 360.0, 380.0, 390.0, 360.0, 415.0, 408.0, 385.0, 358.0, 355.0, 367.0, 360.0, 368.0, 357.0, 380.0, 385.0, 365.0, 365.0, 380.0, 415.0, 365.0, 384.0, 365.0, 378.0, 412.0, 365.0, 395.0, 435.0, 395.0, 380.0, 370.0, 360.0, 380.0, 392.0, 355.0, 390.0, 380.0, 360.0, 375.0, 370.0, 410.0, 390.0, 370.0, 380.0, 360.0, 360.0, 390.0, 380.0, 350.0, 370.0, 370.0, 380.0, 375.0, 365.0, 390.0, 350.0, 385.0, 365.0, 380.0, 360.0, 355.0, 375.0, 378.0, 385.0, 420.0, 390.0, 365.0, 395.0, 365.0, 375.0, 375.0, 393.0, 370.0, 393.0, 340.0, 375.0, 410.0, 390.0, 340.0, 375.0, 355.0, 355.0, 360.0, 340.0, 355.0, 360.0, 350.0, 395.0, 375.0, 420.0, 395.0, 365.0, 385.0, 402.0, 365.0, 417.0, 360.0, 375.0, 476.0, 375.0, 380.0, 384.0, 375.0, 395.0, 385.0, 357.0, 370.0, 380.0, 360.0, 357.0, 385.0, 335.0, 390.0, 400.0, 365.0, 368.0, 345.0, 385.0, 380.0, 375.0, 420.0, 402.0, 380.0, 360.0, 370.0, 385.0, 370.0, 410.0, 410.0, 347.0, 375.0, 375.0, 380.0, 380.0, 370.0, 365.0, 375.0, 375.0, 390.0, 380.0, 380.0, 390.0, 390.0, 365.0, 350.0, 382.0, 375.0, 365.0, 380.0, 365.0, 375.0, 390.0, 345.0, 395.0, 420.0, 360.0, 375.0, 375.0, 320.0, 370.0, 345.0, 370.0, 375.0, 385.0, 350.0, 355.0, 395.0, 370.0, 370.0, 370.0, 395.0, 360.0, 405.0, 355.0, 365.0, 362.0, 360.0, 345.0, 370.0, 360.0, 360.0, 390.0, 357.0, 376.0, 365.0, 353.0, 407.0, 405.0, 385.0, 385.0, 348.0, 340.0, 366.0, 395.0, 368.0, 365.0, 360.0, 355.0, 375.0, 365.0, 388.0, 350.0, 423.0, 380.0, 365.0, 374.0, 380.0, 374.0, 390.0, 378.0, 368.0, 375.0, 365.0, 395.0, 405.0, 392.0, 350.0, 375.0, 360.0, 333.0, 350.0, 350.0, 365.0, 360.0, 370.0, 375.0, 378.0, 365.0, 375.0, 376.0, 370.0, 420.0, 380.0, 353.0, 365.0, 360.0, 357.0, 354.0, 380.0, 374.0, 380.0, 354.0, 360.0, 360.0, 370.0, 397.0, 385.0, 375.0, 375.0, 370.0, 384.0, 364.0, 385.0, 414.0, 430.0, 375.0, 420.0, 335.0, 370.0, 355.0, 395.0, 373.0, 375.0, 414.0, 370.0, 370.0, 387.0, 385.0, 363.0, 360.0, 385.0, 385.0, 380.0, 400.0, 395.0, 430.0, 360.0, 390.0, 345.0, 370.0, 355.0, 365.0, 357.0, 445.0, 390.0, 360.0, 385.0, 360.0, 370.0, 375.0, 390.0, 420.0, 355.0, 370.0, 380.0, 397.0, 390.0, 354.0, 410.0, 390.0, 355.0, 395.0, 355.0, 365.0, 365.0, 355.0, 378.0, 375.0, 405.0, 385.0, 365.0, 390.0, 367.0, 370.0, 353.0, 370.0, 393.0, 365.0, 355.0, 380.0, 338.0, 365.0, 410.0, 395.0, 360.0, 335.0, 355.0, 370.0, 342.0, 347.0, 358.0, 342.0, 354.0, 340.0, 353.0, 355.0, 393.0, 345.0, 345.0, 364.0, 360.0, 373.0, 358.0, 407.0, 350.0, 353.0, 383.0, 370.0, 394.0, 370.0, 380.0, 372.0, 348.0, 397.0, 380.0, 389.0, 394.0, 378.0, 383.0, 377.0, 403.0, 397.0, 358.0, 387.0, 410.0, 355.0, 370.0, 390.0, 350.0, 385.0, 375.0, 364.0, 370.0, 383.0, 354.0, 354.0, 410.0, 382.0, 365.0, 366.0, 405.0, 415.0, 355.0, 368.0, 390.0, 394.0, 395.0, 375.0, 425.0, 384.0, 362.0, 375.0, 360.0, 367.0, 368.0, 385.0, 374.0, 379.0, 390.0, 360.0, 375.0, 340.0, 344.0, 386.0, 343.0, 340.0, 344.0, 365.0, 355.0, 393.0, 380.0, 368.0, 408.0, 360.0, 340.0, 360.0, 325.0, 360.0, 350.0, 388.0, 380.0, 352.0, 400.0, 365.0, 360.0, 383.0, 357.0, 385.0, 362.0, 380.0, 360.0, 425.0, 380.0, 370.0, 335.0, 380.0, 363.0, 400.0, 353.0, 372.0, 360.0, 347.0, 405.0, 354.0, 365.0, 373.0, 387.0, 382.0, 345.0, 425.0, 372.0, 370.0, 340.0, 365.0, 345.0, 373.0, 370.0, 360.0, 377.0, 372.0, 360.0, 385.0, 410.0, 394.0, 355.0, 348.0, 380.0, 367.0, 375.0, 344.0, 410.0, 410.0, 380.0, 375.0, 378.0, 350.0, 385.0, 410.0, 365.0, 415.0, 350.0, 353.0, 380.0, 433.0, 355.0, 370.0, 355.0, 360.0, 340.0, 345.0, 345.0, 390.0, 405.0, 405.0, 368.0, 390.0, 375.0, 355.0, 336.0, 384.0, 392.0, 390.0, 380.0, 430.0, 380.0, 360.0, 364.0, 385.0, 380.0, 420.0, 361.0, 390.0, 394.0, 340.0, 410.0, 390.0, 355.0, 315.0, 350.0, 347.0, 388.0, 362.0, 405.0, 408.0, 383.0, 417.0, 425.0, 370.0, 388.0, 351.0, 397.0, 392.0, 360.0, 375.0, 373.0, 367.0, 380.0, 380.0, 413.0, 395.0, 407.0, 390.0, 385.0, 385.0, 387.0, 413.0, 358.0, 396.0, 373.0, 370.0, 370.0, 410.0, 405.0, 403.0, 378.0, 389.0, 388.0, 385.0, 380.0, 389.0, 365.0, 355.0, 403.0, 357.0, 370.0, 358.0, 390.0, 403.0, 368.0, 340.0, 377.0, 387.0, 420.0, 370.0, 395.0, 386.0, 390.0, 383.0, 377.0, 385.0, 352.0, 380.0, 395.0, 362.0, 405.0, 377.0, 337.0, 398.0, 410.0, 387.0, 345.0, 355.0, 365.0, 395.0, 365.0, 390.0, 365.0, 415.0, 380.0, 358.0, 362.0, 433.0, 370.0, 370.0, 349.0, 363.0, 355.0, 428.0, 335.0, 346.0, 377.0, 403.0, 352.0, 370.0, 380.0, 395.0, 342.0, 365.0, 360.0, 333.0, 346.0, 350.0, 355.0, 424.0, 377.0, 373.0, 370.0, 362.0, 367.0, 426.0, 345.0, 402.0, 352.0, 392.0, 373.0, 397.0, 357.0, 368.0, 373.0, 367.0, 344.0, 415.0, 380.0, 385.0, 355.0, 410.0, 425.0, 365.0, 390.0, 414.0, 358.0, 370.0, 385.0, 417.0, 385.0, 375.0, 354.0, 372.0, 390.0, 395.0, 344.0, 357.0, 448.0, 370.0, 380.0, 398.0, 354.0, 354.0, 345.0, 387.0, 364.0, 387.0, 396.0, 380.0, 378.0, 412.0, 404.0, 405.0, 345.0, 370.0, 402.0, 365.0, 364.0, 377.0, 365.0, 382.0, 416.0, 370.0, 382.0, 394.0, 411.0, 375.0, 376.0, 373.0, 382.0, 410.0, 376.0, 400.0, 362.0, 362.0, 361.0, 353.0, 351.0, 380.0, 410.0, 383.0, 417.0, 351.0, 350.0, 349.0, 366.0, 360.0, 362.0, 383.0, 364.0, 384.0, 384.0, 374.0, 343.0, 360.0, 368.0, 363.0, 365.0, 435.0, 367.0, 410.0, 440.0, 380.0, 357.0, 398.0, 377.0, 372.0, 380.0, 363.0, 362.0, 405.0, 394.0, 355.0, 415.0, 343.0, 417.0, 365.0, 375.0, 360.0, 410.0, 367.0, 377.0, 365.0, 440.0, 385.0, 375.0, 370.0, 440.0, 392.0, 390.0, 410.0, 380.0, 415.0, 400.0, 380.0, 388.0, 365.0, 392.0, 383.0, 375.0, 350.0, 378.0, 420.0, 395.0, 363.0, 357.0, 428.0, 360.0, 395.0, 403.0, 380.0, 392.0, 393.0, 385.0, 420.0, 407.0, 383.0, 390.0, 365.0, 412.0, 390.0, 413.0, 372.0, 387.0, 398.0, 360.0, 365.0, 370.0, 337.0, 377.0, 388.0, 403.0, 402.0, 385.0, 382.0, 412.0, 370.0, 368.0, 383.0, 374.0, 360.0, 397.0, 386.0, 373.0, 352.0, 363.0, 422.0, 397.0, 460.0, 400.0, 397.0, 375.0, 370.0, 357.0, 370.0, 395.0, 380.0, 408.0, 357.0, 355.0, 380.0, 373.0, 397.0, 374.0, 355.0, 390.0, 370.0, 345.0, 357.0, 433.0, 397.0, 368.0, 384.0, 362.0, 400.0, 393.0, 398.0, 372.0, 390.0, 406.0, 385.0, 382.0, 412.0, 395.0, 353.0, 382.0, 384.0, 380.0, 380.0, 362.0, 374.0, 353.0, 408.0, 390.0, 370.0, 400.0, 375.0, 385.0, 410.0, 390.0, 380.0, 420.0, 395.0, 390.0, 375.0, 412.0, 470.0, 405.0, 439.0, 432.0, 435.0, 450.0, 419.0, 435.0, 438.0, 366.0, 419.0, 432.0, 410.0, 411.0, 428.0, 400.0, 448.0, 401.0, 431.0, 405.0, 372.0, 445.0, 410.0, 444.0, 446.0, 396.0, 409.0, 375.0, 434.0, 406.0, 371.0, 406.0, 410.0, 383.0, 424.0, 445.0, 435.0, 409.0, 397.0, 381.0, 373.0, 390.0, 385.0, 381.0, 406.0, 411.0, 377.0, 368.0, 365.0, 395.0, 386.0, 340.0, 391.0, 365.0, 404.0, 379.0, 373.0, 384.0, 411.0, 422.0, 370.0, 371.0, 443.0, 365.0, 419.0, 421.0, 345.0, 418.0, 388.0, 381.0, 397.0, 410.0, 411.0, 401.0, 411.0, 404.0, 390.0, 340.0, 421.0, 396.0, 392.0, 461.0, 351.0, 424.0, 440.0, 375.0, 401.0, 355.0, 377.0, 401.0, 384.0, 425.0, 401.0, 391.0, 370.0, 420.0, 364.0, 409.0, 381.0, 389.0, 361.0, 375.0, 394.0, 418.0, 400.0, 391.0, 396.0, 412.0, 392.0, 365.0, 400.0, 398.0, 385.0, 361.0, 417.0, 360.0, 410.0, 368.0, 390.0, 408.0, 370.0, 366.0, 400.0, 425.0, 367.0, 385.0, 401.0, 365.0, 380.0, 370.0, 346.0, 389.0, 407.0, 412.0, 360.0, 360.0, 410.0, 413.0, 361.0, 365.0, 384.0, 346.0, 330.0, 400.0, 391.0, 350.0, 360.0, 355.0, 400.0, 410.0, 420.0, 360.0, 370.0, 395.0, 360.0, 360.0, 373.0, 375.0, 354.0, 356.0, 425.0, 371.0, 368.0, 380.0, 363.0, 400.0, 365.0, 465.0, 410.0, 400.0, 369.0, 405.0, 395.0, 400.0, 355.0, 388.0, 370.0, 384.0, 446.0, 355.0, 360.0, 400.0, 375.0, 390.0, 341.0, 390.0, 375.0, 406.0, 315.0, 390.0, 422.0, 350.0, 429.0, 355.0, 351.0, 370.0, 365.0, 378.0, 367.0, 431.0, 421.0, 423.0, 375.0, 385.0, 364.0, 400.0, 415.0, 410.0, 370.0, 380.0, 370.0, 355.0, 360.0, 355.0, 425.0, 395.0, 355.0, 385.0, 375.0, 310.0, 380.0, 375.0, 395.0, 395.0, 410.0, 381.0, 348.0, 395.0, 394.0, 375.0, 395.0, 367.0, 392.0, 352.0, 375.0, 395.0, 415.0, 442.0, 350.0, 349.0, 392.0, 371.0, 375.0, 357.0, 400.0, 376.0, 375.0, 362.0, 382.0, 375.0, 361.0, 401.0, 405.0, 381.0, 363.0, 370.0, 395.0, 362.0, 382.0, 415.0, 395.0, 395.0, 375.0, 330.0, 424.0, 374.0, 405.0, 364.0, 356.0, 401.0, 360.0, 365.0, 379.0, 408.0, 365.0, 368.0, 391.0, 421.0, 380.0, 365.0, 395.0, 378.0, 405.0, 367.0, 378.0, 410.0, 389.0, 395.0, 401.0, 376.0, 388.0, 379.0, 396.0, 390.0, 361.0, 377.0, 409.0, 355.0, 388.0, 384.0, 361.0, 391.0, 418.0, 401.0, 385.0, 371.0, 360.0, 380.0, 395.0, 385.0, 424.0, 390.0, 378.0, 390.0, 368.0, 354.0, 414.0, 391.0, 372.0, 378.0, 374.0, 364.0, 384.0, 395.0, 365.0, 379.0, 370.0, 360.0, 375.0, 368.0, 379.0, 395.0, 368.0, 366.0, 375.0, 385.0, 301.0, 365.0, 375.0, 360.0, 371.0, 409.0, 390.0, 385.0, 381.0, 380.0, 380.0, 369.0, 380.0, 370.0, 365.0, 395.0, 388.0, 394.0, 395.0, 385.0, 391.0, 401.0, 386.0, 375.0, 391.0, 390.0, 358.0, 379.0, 374.0, 411.0, 384.0, 396.0, 354.0, 380.0, 400.0, 385.0, 405.0, 385.0, 394.0, 399.0, 364.0, 364.0, 370.0, 345.0, 369.0, 385.0, 379.0, 370.0, 390.0, 400.0, 382.0, 393.0, 399.0, 369.0, 419.0, 365.0, 382.0, 381.0, 372.0, 386.0, 365.0, 375.0, 434.0, 375.0, 405.0, 374.0, 371.0, 408.0, 356.0, 365.0, 372.0, 379.0, 376.0, 400.0, 413.0, 379.0, 395.0, 369.0, 399.0, 389.0, 410.0, 397.0, 376.0, 390.0, 385.0, 423.0, 349.0, 385.0, 415.0, 371.0, 410.0, 379.0, 367.0, 385.0, 401.0, 390.0, 404.0, 385.0, 390.0, 388.0, 374.0, 384.0, 379.0, 384.0, 395.0, 395.0, 370.0, 398.0, 389.0, 388.0, 385.0, 402.0, 387.0, 390.0, 358.0, 362.0, 371.0, 330.0, 355.0, 389.0, 385.0, 380.0, 341.0, 413.0, 338.0, 417.0, 409.0, 370.0, 412.0, 382.0, 387.0, 376.0, 394.0, 370.0, 384.0, 394.0, 400.0, 374.0, 368.0, 386.0, 365.0, 395.0, 385.0, 378.0, 371.0, 360.0, 413.0, 395.0, 401.0, 382.0, 380.0, 380.0, 345.0, 360.0, 345.0, 365.0, 370.0, 380.0, 408.0, 374.0, 445.0, 380.0, 354.0, 374.0, 380.0, 350.0, 375.0, 365.0, 368.0, 374.0, 340.0, 386.0, 375.0, 388.0, 395.0, 375.0, 414.0, 380.0, 351.0, 375.0, 350.0, 380.0, 405.0, 345.0, 365.0, 370.0, 370.0, 362.0, 335.0, 375.0, 414.0, 370.0, 375.0, 350.0, 365.0, 405.0, 360.0, 378.0, 364.0, 335.0, 375.0, 380.0, 370.0, 375.0, 395.0, 356.0, 395.0, 375.0, 388.0, 380.0, 370.0, 370.0, 355.0, 410.0, 360.0, 420.0, 380.0, 390.0, 365.0, 370.0, 345.0, 374.0, 380.0, 370.0, 390.0, 389.0, 363.0, 400.0, 410.0, 395.0, 390.0, 395.0, 351.0, 392.0, 385.0, 385.0, 365.0, 394.0, 365.0, 385.0, 405.0, 430.0, 395.0, 350.0, 425.0, 360.0, 385.0, 328.0, 380.0, 380.0, 375.0, 375.0, 375.0, 383.0, 360.0, 366.0, 378.0, 355.0, 395.0, 384.0, 364.0, 364.0, 355.0, 386.0, 375.0, 369.0, 374.0, 386.0, 394.0, 414.0, 399.0, 390.0, 386.0, 346.0, 441.0, 374.0, 420.0, 360.0, 365.0, 332.0, 419.0, 438.0, 390.0, 389.0, 432.0, 360.0, 342.0, 383.0, 382.0, 404.0, 342.0, 395.0, 395.0, 355.0, 391.0, 358.0, 390.0, 372.0, 373.0, 400.0, 402.0, 385.0, 400.0, 392.0, 398.0, 375.0, 418.0, 380.0, 410.0, 435.0, 400.0, 320.0, 385.0, 359.0, 370.0, 440.0, 354.0, 351.0, 365.0, 400.0, 385.0, 418.0, 390.0, 413.0, 395.0, 410.0, 365.0, 400.0, 375.0, 358.0, 385.0, 365.0, 380.0, 390.0, 408.0, 395.0, 395.0, 355.0, 365.0, 375.0, 395.0, 358.0, 375.0, 362.0, 405.0, 384.0, 410.0, 440.0, 405.0, 415.0, 395.0, 340.0, 463.0, 369.0, 374.0, 411.0, 432.0, 389.0, 354.0, 350.0, 381.0, 358.0, 375.0, 361.0, 370.0, 360.0, 370.0, 410.0, 410.0, 362.0, 370.0, 390.0, 354.0, 370.0, 398.0, 389.0, 390.0, 356.0, 391.0, 369.0, 384.0, 379.0, 399.0, 370.0, 374.0, 354.0, 369.0, 379.0, 386.0, 367.0, 389.0, 365.0, 364.0, 346.0, 425.0, 435.0, 369.0, 358.0, 384.0, 370.0, 412.0, 368.0, 423.0, 402.0, 396.0, 384.0, 383.0, 389.0, 389.0, 365.0, 366.0, 380.0, 375.0, 383.0, 374.0, 360.0, 385.0, 376.0, 365.0, 396.0, 376.0, 371.0, 389.0, 411.0, 390.0, 384.0, 377.0, 381.0, 377.0, 412.0, 381.0]\n",
      "1431 358\n",
      "[407, 364, 380, 422, 374, 370, 354, 345, 378, 378, 370, 400, 363, 355, 360, 373, 403, 414, 400, 370, 400, 400, 382, 415, 376, 385, 364, 360, 454, 380, 345, 367, 382, 357, 430, 400, 395, 407, 400, 362, 375, 382, 368, 366, 335, 353, 400, 383, 350, 387, 380, 400, 380, 365, 374, 364, 350, 365, 382, 370, 388, 385, 370, 365, 380, 394, 414, 387, 370, 380, 358, 342, 417, 375, 425, 384, 350, 390, 343, 420, 355, 365, 380, 360, 364, 365, 365, 375, 355, 400, 401, 405, 398, 360, 350, 392, 382, 365, 400, 393, 390, 395, 375, 400, 340, 370, 385, 465, 430, 371, 371, 366, 397, 360, 382, 375, 385, 410, 393, 375, 365, 415, 366, 430, 390, 400, 360, 355, 403, 430, 410, 411, 350, 365, 345, 420, 370, 376, 365, 395, 372, 415, 385, 355, 360, 375, 385, 352, 370, 355, 350, 355, 360, 380, 390, 360, 415, 408, 385, 358, 355, 367, 360, 368, 357, 380, 385, 365, 365, 380, 415, 365, 384, 365, 378, 412, 365, 395, 435, 395, 380, 370, 360, 380, 392, 355, 390, 380, 360, 375, 370, 410, 390, 370, 380, 360, 360, 390, 380, 350, 370, 370, 380, 375, 365, 390, 350, 385, 365, 380, 360, 355, 375, 378, 385, 420, 390, 365, 395, 365, 375, 375, 393, 370, 393, 340, 375, 410, 390, 340, 375, 355, 355, 360, 340, 355, 360, 350, 395, 375, 420, 395, 365, 385, 402, 365, 417, 360, 375, 476, 375, 380, 384, 375, 395, 385, 357, 370, 380, 360, 357, 385, 335, 390, 400, 365, 368, 345, 385, 380, 375, 420, 402, 380, 360, 370, 385, 370, 410, 410, 347, 375, 375, 380, 380, 370, 365, 375, 375, 390, 380, 380, 390, 390, 365, 350, 382, 375, 365, 380, 365, 375, 390, 345, 395, 420, 360, 375, 375, 320, 370, 345, 370, 375, 385, 350, 355, 395, 370, 370, 370, 395, 360, 405, 355, 365, 362, 360, 345, 370, 360, 360, 390, 357, 376, 365, 353, 407, 405, 385, 385, 348, 340, 366, 395, 368, 365, 360, 355, 375, 365, 388, 350, 423, 380, 365, 374, 380, 374, 390, 378, 368, 375, 365, 395, 405, 392, 350, 375, 360, 333, 350, 350, 365, 360, 370, 375, 378, 365, 375, 376, 370, 420, 380, 353, 365, 360, 357, 354, 380, 374, 380, 354, 360, 360, 370, 397, 385, 375, 375, 370, 384, 364, 385, 414, 430, 375, 420, 335, 370, 355, 395, 373, 375, 414, 370, 370, 387, 385, 363, 360, 385, 385, 380, 400, 395, 430, 360, 390, 345, 370, 355, 365, 357, 445, 390, 360, 385, 360, 370, 375, 390, 420, 355, 370, 380, 397, 390, 354, 410, 390, 355, 395, 355, 365, 365, 355, 378, 375, 405, 385, 365, 390, 367, 370, 353, 370, 393, 365, 355, 380, 338, 365, 410, 395, 360, 335, 355, 370, 342, 347, 358, 342, 354, 340, 353, 355, 393, 345, 345, 364, 360, 373, 358, 407, 350, 353, 383, 370, 394, 370, 380, 372, 348, 397, 380, 389, 394, 378, 383, 377, 403, 397, 358, 387, 410, 355, 370, 390, 350, 385, 375, 364, 370, 383, 354, 354, 410, 382, 365, 366, 405, 415, 355, 368, 390, 394, 395, 375, 425, 384, 362, 375, 360, 367, 368, 385, 374, 379, 390, 360, 375, 340, 344, 386, 343, 340, 344, 365, 355, 393, 380, 368, 408, 360, 340, 360, 325, 360, 350, 388, 380, 352, 400, 365, 360, 383, 357, 385, 362, 380, 360, 425, 380, 370, 335, 380, 363, 400, 353, 372, 360, 347, 405, 354, 365, 373, 387, 382, 345, 425, 372, 370, 340, 365, 345, 373, 370, 360, 377, 372, 360, 385, 410, 394, 355, 348, 380, 367, 375, 344, 410, 410, 380, 375, 378, 350, 385, 410, 365, 415, 350, 353, 380, 433, 355, 370, 355, 360, 340, 345, 345, 390, 405, 405, 368, 390, 375, 355, 336, 384, 392, 390, 380, 430, 380, 360, 364, 385, 380, 420, 361, 390, 394, 340, 410, 390, 355, 315, 350, 347, 388, 362, 405, 408, 383, 417, 425, 370, 388, 351, 397, 392, 360, 375, 373, 367, 380, 380, 413, 395, 407, 390, 385, 385, 387, 413, 358, 396, 373, 370, 370, 410, 405, 403, 378, 389, 388, 385, 380, 389, 365, 355, 403, 357, 370, 358, 390, 403, 368, 340, 377, 387, 420, 370, 395, 386, 390, 383, 377, 385, 352, 380, 395, 362, 405, 377, 337, 398, 410, 387, 345, 355, 365, 395, 365, 390, 365, 415, 380, 358, 362, 433, 370, 370, 349, 363, 355, 428, 335, 346, 377, 403, 352, 370, 380, 395, 342, 365, 360, 333, 346, 350, 355, 424, 377, 373, 370, 362, 367, 426, 345, 402, 352, 392, 373, 397, 357, 368, 373, 367, 344, 415, 380, 385, 355, 410, 425, 365, 390, 414, 358, 370, 385, 417, 385, 375, 354, 372, 390, 395, 344, 357, 448, 370, 380, 398, 354, 354, 345, 387, 364, 387, 396, 380, 378, 412, 404, 405, 345, 370, 402, 365, 364, 377, 365, 382, 416, 370, 382, 394, 411, 375, 376, 373, 382, 410, 376, 400, 362, 362, 361, 353, 351, 380, 410, 383, 417, 351, 350, 349, 366, 360, 362, 383, 364, 384, 384, 374, 343, 360, 368, 363, 365, 435, 367, 410, 440, 380, 357, 398, 377, 372, 380, 363, 362, 405, 394, 355, 415, 343, 417, 365, 375, 360, 410, 367, 377, 365, 440, 385, 375, 370, 440, 392, 390, 410, 380, 415, 400, 380, 388, 365, 392, 383, 375, 350, 378, 420, 395, 363, 357, 428, 360, 395, 403, 380, 392, 393, 385, 420, 407, 383, 390, 365, 412, 390, 413, 372, 387, 398, 360, 365, 370, 337, 377, 388, 403, 402, 385, 382, 412, 370, 368, 383, 374, 360, 397, 386, 373, 352, 363, 422, 397, 460, 400, 397, 375, 370, 357, 370, 395, 380, 408, 357, 355, 380, 373, 397, 374, 355, 390, 370, 345, 357, 433, 397, 368, 384, 362, 400, 393, 398, 372, 390, 406, 385, 382, 412, 395, 353, 382, 384, 380, 380, 362, 374, 353, 408, 390, 370, 400, 375, 385, 410, 390, 380, 420, 395, 390, 375, 412, 470, 405, 439, 432, 435, 450, 419, 435, 438, 366, 419, 432, 410, 411, 428, 400, 448, 401, 431, 405, 372, 445, 410, 444, 446, 396, 409, 375, 434, 406, 371, 406, 410, 383, 424, 445, 435, 409, 397, 381, 373, 390, 385, 381, 406, 411, 377, 368, 365, 395, 386, 340, 391, 365, 404, 379, 373, 384, 411, 422, 370, 371, 443, 365, 419, 421, 345, 418, 388, 381, 397, 410, 411, 401, 411, 404, 390, 340, 421, 396, 392, 461, 351, 424, 440, 375, 401, 355, 377, 401, 384, 425, 401, 391, 370, 420, 364, 409, 381, 389, 361, 375, 394, 418, 400, 391, 396, 412, 392, 365, 400, 398, 385, 361, 417, 360, 410, 368, 390, 408, 370, 366, 400, 425, 367, 385, 401, 365, 380, 370, 346, 389, 407, 412, 360, 360, 410, 413, 361, 365, 384, 346, 330, 400, 391, 350, 360, 355, 400, 410, 420, 360, 370, 395, 360, 360, 373, 375, 354, 356, 425, 371, 368, 380, 363, 400, 365, 465, 410, 400, 369, 405, 395, 400, 355, 388, 370, 384, 446, 355, 360, 400, 375, 390, 341, 390, 375, 406, 315, 390, 422, 350, 429, 355, 351, 370, 365, 378, 367, 431, 421, 423, 375, 385, 364, 400, 415, 410, 370, 380, 370, 355, 360, 355, 425, 395, 355, 385, 375, 310, 380, 375, 395, 395, 410, 381, 348, 395, 394, 375, 395, 367, 392, 352, 375, 395, 415, 442, 350, 349, 392, 371, 375, 357, 400, 376, 375, 362, 382, 375, 361, 401, 405, 381, 363, 370, 395, 362, 382, 415, 395, 395, 375, 330, 424, 374, 405, 364, 356, 401, 360, 365, 379, 408, 365, 368, 391, 421, 380, 365, 395, 378, 405, 367, 378, 410, 389, 395, 401, 376, 388, 379, 396, 390, 361, 377, 409, 355, 388, 384, 361, 391, 418, 401, 385, 371, 360, 380, 395, 385, 424, 390, 378, 390, 368, 354, 414, 391, 372, 378, 374, 364, 384, 395, 365, 379, 370, 360, 375, 368, 379, 395, 368, 366, 375, 385, 301, 365, 375, 360, 371, 409, 390, 385, 381, 380, 380, 369, 380, 370, 365, 395, 388, 394, 395, 385, 391, 401, 386, 375, 391, 390, 358, 379, 374, 411, 384, 396, 354, 380, 400, 385, 405, 385, 394, 399, 364, 364, 370, 345, 369, 385, 379, 370, 390, 400, 382, 393, 399, 369, 419, 365, 382, 381, 372, 386, 365, 375, 434, 375, 405, 374, 371, 408, 356, 365, 372, 379, 376, 400, 413, 379, 395, 369, 399, 389, 410, 397, 376, 390, 385, 423, 349, 385, 415, 371, 410, 379, 367, 385, 401, 390, 404, 385, 390, 388, 374, 384, 379, 384, 395, 395, 370, 398, 389, 388, 385, 402, 387, 390, 358, 362, 371, 330, 355, 389, 385, 380, 341, 413, 338, 417, 409, 370, 412, 382, 387, 376, 394, 370, 384, 394, 400, 374, 368, 386, 365, 395, 385, 378, 371, 360, 413, 395, 401, 382, 380, 380, 345, 360, 345, 365, 370, 380, 408, 374, 445, 380, 354, 374, 380, 350, 375, 365, 368, 374, 340, 386, 375, 388, 395, 375, 414, 380, 351, 375, 350, 380, 405, 345, 365, 370, 370, 362, 335, 375, 414, 370, 375, 350, 365, 405, 360, 378, 364, 335, 375, 380, 370, 375, 395, 356, 395, 375, 388, 380, 370, 370, 355, 410, 360, 420, 380, 390, 365, 370, 345, 374, 380, 370, 390, 389, 363, 400, 410, 395, 390, 395, 351, 392, 385, 385, 365, 394, 365, 385, 405, 430, 395, 350, 425, 360, 385, 328, 380, 380, 375, 375, 375, 383, 360, 366, 378, 355, 395, 384, 364, 364, 355, 386, 375, 369, 374, 386, 394, 414, 399, 390, 386, 346, 441, 374, 420, 360, 365, 332, 419, 438, 390, 389, 432, 360, 342, 383, 382, 404, 342, 395, 395, 355, 391, 358, 390, 372, 373, 400, 402, 385, 400, 392, 398, 375, 418, 380, 410, 435, 400, 320, 385, 359, 370, 440, 354, 351, 365, 400, 385, 418, 390, 413, 395, 410, 365, 400, 375, 358, 385, 365, 380, 390, 408, 395, 395, 355, 365, 375, 395, 358, 375, 362, 405, 384, 410, 440, 405, 415, 395, 340, 463, 369, 374, 411, 432, 389, 354, 350, 381, 358, 375, 361, 370, 360, 370, 410, 410, 362, 370, 390, 354, 370, 398, 389, 390, 356, 391, 369, 384, 379, 399, 370, 374, 354, 369, 379, 386, 367, 389, 365, 364, 346, 425, 435, 369, 358, 384, 370, 412, 368, 423, 402, 396, 384, 383, 389, 389, 365, 366, 380, 375, 383, 374, 360, 385, 376, 365, 396, 376, 371, 389, 411, 390, 384, 377, 381, 377, 412, 381]\n",
      "301\n",
      "(1789, 6)\n",
      "Predicted class [103  69  74 109  79  84  79  84  54  74  74  74 109  64  69  94  64  94\n",
      "  74  74  89  54  74  89  99  94  74  59  94  74  74  84  94  64  64  94\n",
      "  89  94  99  74  94  14  59  64  34  79  74  94  74  59 100  54  89  94\n",
      "  89  99  74  74  74  94  64  64  79  89  59  64  94  89  80  74  74  69\n",
      "  59  79 114  99  74  69  74  64  79  54  64  64  59  89  74 164  69  59\n",
      "  74  64  64  59  59  74  89  64 111  64 149  99  59  94 120  64  94  94\n",
      "  64 175  54  74  79  74  59  79  64  79  74  64  89  64  74  59  79  32\n",
      "  59  74  79  84  64  74  54  84  89  80  64  79  64  64 121  74  74  54\n",
      "  74  64  64  24  80  74  79  94  74  59  94  64  79  89  74  79  54  74\n",
      "  79  64  94  64  84  84 159  89  59 153  64  80  54  74  64  84  84  64\n",
      "  59  69  74  64  84  89  54  59  79  54  59  59  74  39  79  64 159  94\n",
      "  94  64  59  94  64 139  39  59  39 105 104  79  94 114  32  64  69  64\n",
      " 159  64  64  94  69  64  64  84  59  69  94  84  74  84  89  84  84  69\n",
      "  64  74  89  84  54  54  64  59  84  69  19  59  79  69 139  64 104  89\n",
      " 164  79  84  69  64  79  79  54  69  80  99  74  54  19  59  94  74  79\n",
      "  54  49  69 121 164  94  94  94  64 109  74  64  84  79  64  54  64  94\n",
      "  64  74  64  79  74  64  89 109  59  54 164  64  89 159  94  69  64  89\n",
      "  54  64  74  69  84  59  59  64  84  74  74  89  74  74  64 109  94  69\n",
      "  64  74  74  94  64 109  64  79  89  94  64  64  59  84  94  74  74  74\n",
      "  64  64  74  69  64  99  69  89  99  94  64  64  69  89  89  79]\n",
      "real class [99, 112, 78, 94, 68, 98, 88, 109, 96, 75, 89, 84, 122, 48, 84, 114, 70, 109, 78, 66, 84, 100, 89, 103, 84, 89, 87, 73, 83, 78, 83, 94, 94, 69, 97, 88, 87, 84, 101, 86, 89, 57, 61, 70, 29, 54, 88, 84, 79, 40, 112, 37, 116, 108, 69, 111, 81, 86, 75, 93, 69, 83, 93, 99, 73, 67, 85, 64, 94, 84, 77, 70, 59, 112, 94, 100, 81, 79, 79, 44, 59, 44, 64, 69, 79, 107, 73, 144, 79, 53, 73, 79, 49, 74, 64, 67, 73, 39, 85, 74, 87, 94, 74, 113, 79, 50, 74, 49, 79, 104, 44, 64, 69, 69, 61, 34, 74, 113, 69, 74, 49, 64, 104, 59, 77, 63, 34, 74, 79, 69, 74, 94, 55, 94, 74, 87, 79, 69, 69, 54, 109, 59, 119, 79, 89, 64, 69, 44, 73, 79, 69, 89, 88, 62, 99, 109, 94, 89, 94, 50, 91, 84, 84, 64, 93, 64, 84, 104, 129, 94, 49, 124, 59, 84, 27, 79, 79, 74, 74, 74, 82, 59, 65, 77, 54, 94, 83, 63, 63, 54, 85, 74, 68, 73, 85, 93, 113, 98, 89, 85, 45, 140, 73, 119, 59, 64, 31, 118, 137, 89, 88, 131, 59, 41, 82, 81, 103, 41, 94, 94, 54, 90, 57, 89, 71, 72, 99, 101, 84, 99, 91, 97, 74, 117, 79, 109, 134, 99, 19, 84, 58, 69, 139, 53, 50, 64, 99, 84, 117, 89, 112, 94, 109, 64, 99, 74, 57, 84, 64, 79, 89, 107, 94, 94, 54, 64, 74, 94, 57, 74, 61, 104, 83, 109, 139, 104, 114, 94, 39, 162, 68, 73, 110, 131, 88, 53, 49, 80, 57, 74, 60, 69, 59, 69, 109, 109, 61, 69, 89, 53, 69, 97, 88, 89, 55, 90, 68, 83, 78, 98, 69, 73, 53, 68, 78, 85, 66, 88, 64, 63, 45, 124, 134, 68, 57, 83, 69, 111, 67, 122, 101, 95, 83, 82, 88, 88, 64, 65, 79, 74, 82, 73, 59, 84, 75, 64, 95, 75, 70, 88, 110, 89, 83, 76, 80, 76, 111, 80]\n",
      "Score for test data from 27 to 50 of neck circum.: 0.055865921787709494\n",
      "N test sample 358\n",
      "Score for test data from 27 to 50 of neck circum.: 0.8435754189944135\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#pandas를 Numpy list 의 tuple로 변환합니다.\n",
    "my_data = np.array(sizeKoreaMale2040.to_records())\n",
    "#list의 개수 반환 , (1789,)\n",
    "print(\"my_data shape :{}\".format(my_data.shape))\n",
    "#list내의 element개수 반환 (31)\n",
    "print(\"{}\".format(len(my_data[0])))\n",
    "#0.02 성별,1.06_나이_반올림,2.001_오른쪽어깨경사각,3.002_왼쪽어깨경사각,4.003_키,5.005_목뒤높이\n",
    "#6.017_샅높이, 7.031_몸무게, 8.037_목둘레, 9.038_목밑둘레, 10.039_가슴둘레, 11.040_젖가슴둘레\n",
    "#12.042_허리둘레, 13.043_배꼽수준허리둘레, 14.044_배둘레, 15.045_엉덩이둘레, 16.052_총길이\n",
    "#17.054_어깨사이길이, 18.055_어깨가쪽사이길이, 19.063_위팔길이, 20.064_팔길이, 21.065_팔안쪽길이, 22.069_다리가쪽길이\n",
    "#23.111_머리둘레, 24.121_넙다리둘레, 25.122_넙다리중간둘레, 26.123_무릎둘레, 27.125_장딴지둘레, 28.130_위팔둘레, 29.131_팔꿈치둘레\n",
    "\n",
    "# access tuple access in the list\n",
    "# list의 tuple의 9번째 Element로 저장된 목둘레 길이를 접근합니다.\n",
    "print(\"{}\".format([x[9] for x in my_data]))\n",
    "\n",
    "(row,column)= my_data.shape[0], len(my_data[0])\n",
    "#전체 dataset길이의 80%를 training data크기로 지정\n",
    "n_training = math.floor(row * 0.8)\n",
    "n_testing = row - n_training;\n",
    "print(n_training, n_testing)\n",
    "\n",
    "#목둘레\n",
    "low_value = 301\n",
    "v_neck_around = [int(x[9]) for x in my_data]\n",
    "min_v_neck = min(v_neck_around)  #in current dataset, min value is 301, however we set the minimum value as 270\n",
    "print(v_neck_around)\n",
    "print(min_v_neck)\n",
    "# Test dataset을 Class로 표현\n",
    "Y_Class = [int(x-low_value) for x in v_neck_around]\n",
    "\n",
    "#import data\n",
    "#예측 대상값은 : 목둘레\n",
    "# training, testing data를 분배함\n",
    "# 12-젖가슴둘레,13-배꼽수준허리둘레,14 -배둘레, 15-엉덩이둘레, 28-위팔둘레, 7-몸무게\n",
    "TX1 = [float(x[7]) for x in my_data]\n",
    "TX2 = [float(x[12].replace(',','')) for x in my_data]\n",
    "TX3 = [float(x[13].replace(',','')) for x in my_data]\n",
    "TX4 = [float(x[14].replace(',','')) for x in my_data]\n",
    "TX5 = [float(x[15].replace(',','')) for x in my_data]\n",
    "TX6 = [x[28] for x in my_data]\n",
    "TX = np.column_stack((TX1, TX2, TX3, TX4, TX5, TX6))\n",
    "print(\"{}\".format(TX.shape))\n",
    "# \n",
    "X_train = TX[1:n_training, :]\n",
    "y_train = np.array(Y_Class[1:n_training])\n",
    "X_test = TX[n_training:,:]\n",
    "Y_test = Y_Class[n_training:]\n",
    "\n",
    "h=.02 #step size in the mesh\n",
    "#추가 Option 확인 ~ http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "logistic = LogisticRegression(C=1e7,intercept_scaling=2.0,solver='liblinear')\n",
    "\n",
    "#we create an instance of Neighbours Classifier and fit the data\n",
    "logistic.fit(X_train,y_train)\n",
    "\n",
    "print ('Predicted class {0}'.format(logistic.predict(X_test)))\n",
    "print ('real class {0}'.format(Y_test))\n",
    "print ('Score for test data from 27 to 50 of neck circum.: {0}'.format(logistic.score(X_test,Y_test)))\n",
    "\n",
    "Result_Dec=logistic.predict(X_test)\n",
    "prediction = .0\n",
    "n_test_samples = len(Y_test)\n",
    "print('N test sample {0}'.format(n_test_samples))\n",
    "for number in range(0,n_test_samples):\n",
    "    if(abs(round(Result_Dec[number])-Y_test[number])<=25.0):\n",
    "        prediction += 1.0\n",
    "prediction /= n_test_samples\n",
    "\n",
    "print ('Score for test data from 27 to 50 of neck circum.: {0}'.format(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class [ 69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69\n",
      "  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69\n",
      "  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69\n",
      "  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69\n",
      "  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69\n",
      "  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69\n",
      "  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69\n",
      "  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69\n",
      "  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69\n",
      "  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69\n",
      "  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69\n",
      "  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69\n",
      "  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69\n",
      "  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69\n",
      "  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69\n",
      "  69  69  69  69  69  69  69  69  69  69  69  69 110  69  69  69  69  69\n",
      "  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69\n",
      "  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69\n",
      "  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69\n",
      "  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69]\n",
      "real class [99, 112, 78, 94, 68, 98, 88, 109, 96, 75, 89, 84, 122, 48, 84, 114, 70, 109, 78, 66, 84, 100, 89, 103, 84, 89, 87, 73, 83, 78, 83, 94, 94, 69, 97, 88, 87, 84, 101, 86, 89, 57, 61, 70, 29, 54, 88, 84, 79, 40, 112, 37, 116, 108, 69, 111, 81, 86, 75, 93, 69, 83, 93, 99, 73, 67, 85, 64, 94, 84, 77, 70, 59, 112, 94, 100, 81, 79, 79, 44, 59, 44, 64, 69, 79, 107, 73, 144, 79, 53, 73, 79, 49, 74, 64, 67, 73, 39, 85, 74, 87, 94, 74, 113, 79, 50, 74, 49, 79, 104, 44, 64, 69, 69, 61, 34, 74, 113, 69, 74, 49, 64, 104, 59, 77, 63, 34, 74, 79, 69, 74, 94, 55, 94, 74, 87, 79, 69, 69, 54, 109, 59, 119, 79, 89, 64, 69, 44, 73, 79, 69, 89, 88, 62, 99, 109, 94, 89, 94, 50, 91, 84, 84, 64, 93, 64, 84, 104, 129, 94, 49, 124, 59, 84, 27, 79, 79, 74, 74, 74, 82, 59, 65, 77, 54, 94, 83, 63, 63, 54, 85, 74, 68, 73, 85, 93, 113, 98, 89, 85, 45, 140, 73, 119, 59, 64, 31, 118, 137, 89, 88, 131, 59, 41, 82, 81, 103, 41, 94, 94, 54, 90, 57, 89, 71, 72, 99, 101, 84, 99, 91, 97, 74, 117, 79, 109, 134, 99, 19, 84, 58, 69, 139, 53, 50, 64, 99, 84, 117, 89, 112, 94, 109, 64, 99, 74, 57, 84, 64, 79, 89, 107, 94, 94, 54, 64, 74, 94, 57, 74, 61, 104, 83, 109, 139, 104, 114, 94, 39, 162, 68, 73, 110, 131, 88, 53, 49, 80, 57, 74, 60, 69, 59, 69, 109, 109, 61, 69, 89, 53, 69, 97, 88, 89, 55, 90, 68, 83, 78, 98, 69, 73, 53, 68, 78, 85, 66, 88, 64, 63, 45, 124, 134, 68, 57, 83, 69, 111, 67, 122, 101, 95, 83, 82, 88, 88, 64, 65, 79, 74, 82, 73, 59, 84, 75, 64, 95, 75, 70, 88, 110, 89, 83, 76, 80, 76, 111, 80]\n",
      "Score for test data from 27 to 50 of neck circum.: 0.055865921787709494\n",
      "N test sample 358\n",
      "Score for test data from 27 to 50 of neck circum.: 0.8184357541899442\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC(C=1.0, cache_size=200, coef0=0.0, \n",
    "    decision_function_shape='ovr', degree=23, gamma=0.265, kernel='rbf', #0.265\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.0001, verbose=False)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print ('Predicted class {0}'.format(clf.predict(X_test)))\n",
    "print ('real class {0}'.format(Y_test))\n",
    "print ('Score for test data from 27 to 50 of neck circum.: {0}'.format(clf.score(X_test,Y_test)))\n",
    "\n",
    "Result_Dec=clf.predict(X_test)\n",
    "prediction = .0\n",
    "n_test_samples = len(Y_test)\n",
    "print('N test sample {0}'.format(n_test_samples))\n",
    "for number in range(0,n_test_samples):\n",
    "    if(abs(round(Result_Dec[number])-Y_test[number])<=30.0):\n",
    "        prediction += 1.0\n",
    "prediction /= n_test_samples\n",
    "\n",
    "print ('Score for test data from 27 to 50 of neck circum.: {0}'.format(prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class [ 69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69\n",
      "  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69\n",
      "  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69\n",
      "  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69\n",
      "  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69\n",
      "  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69\n",
      "  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69\n",
      "  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69\n",
      "  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69\n",
      "  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69\n",
      "  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69\n",
      "  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69\n",
      "  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69\n",
      "  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69\n",
      "  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69\n",
      "  69  69  69  69  69  69  69  69  69  69  69  69 110  69  69  69  69  69\n",
      "  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69\n",
      "  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69\n",
      "  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69\n",
      "  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69]\n",
      "real class [99, 112, 78, 94, 68, 98, 88, 109, 96, 75, 89, 84, 122, 48, 84, 114, 70, 109, 78, 66, 84, 100, 89, 103, 84, 89, 87, 73, 83, 78, 83, 94, 94, 69, 97, 88, 87, 84, 101, 86, 89, 57, 61, 70, 29, 54, 88, 84, 79, 40, 112, 37, 116, 108, 69, 111, 81, 86, 75, 93, 69, 83, 93, 99, 73, 67, 85, 64, 94, 84, 77, 70, 59, 112, 94, 100, 81, 79, 79, 44, 59, 44, 64, 69, 79, 107, 73, 144, 79, 53, 73, 79, 49, 74, 64, 67, 73, 39, 85, 74, 87, 94, 74, 113, 79, 50, 74, 49, 79, 104, 44, 64, 69, 69, 61, 34, 74, 113, 69, 74, 49, 64, 104, 59, 77, 63, 34, 74, 79, 69, 74, 94, 55, 94, 74, 87, 79, 69, 69, 54, 109, 59, 119, 79, 89, 64, 69, 44, 73, 79, 69, 89, 88, 62, 99, 109, 94, 89, 94, 50, 91, 84, 84, 64, 93, 64, 84, 104, 129, 94, 49, 124, 59, 84, 27, 79, 79, 74, 74, 74, 82, 59, 65, 77, 54, 94, 83, 63, 63, 54, 85, 74, 68, 73, 85, 93, 113, 98, 89, 85, 45, 140, 73, 119, 59, 64, 31, 118, 137, 89, 88, 131, 59, 41, 82, 81, 103, 41, 94, 94, 54, 90, 57, 89, 71, 72, 99, 101, 84, 99, 91, 97, 74, 117, 79, 109, 134, 99, 19, 84, 58, 69, 139, 53, 50, 64, 99, 84, 117, 89, 112, 94, 109, 64, 99, 74, 57, 84, 64, 79, 89, 107, 94, 94, 54, 64, 74, 94, 57, 74, 61, 104, 83, 109, 139, 104, 114, 94, 39, 162, 68, 73, 110, 131, 88, 53, 49, 80, 57, 74, 60, 69, 59, 69, 109, 109, 61, 69, 89, 53, 69, 97, 88, 89, 55, 90, 68, 83, 78, 98, 69, 73, 53, 68, 78, 85, 66, 88, 64, 63, 45, 124, 134, 68, 57, 83, 69, 111, 67, 122, 101, 95, 83, 82, 88, 88, 64, 65, 79, 74, 82, 73, 59, 84, 75, 64, 95, 75, 70, 88, 110, 89, 83, 76, 80, 76, 111, 80]\n",
      "Score for test data from 27 to 50 of neck circum.: 0.055865921787709494\n",
      "N test sample 358\n",
      "Score for test data from 27 to 50 of neck circum.: 0.8184357541899442\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(C=1000.0, cache_size=200, coef0=0.0, \n",
    "    decision_function_shape='ovr', degree=23, gamma=0.265, kernel='rbf', #0.265\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.0001, verbose=False)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print ('Predicted class {0}'.format(clf.predict(X_test)))\n",
    "print ('real class {0}'.format(Y_test))\n",
    "print ('Score for test data from 27 to 50 of neck circum.: {0}'.format(clf.score(X_test,Y_test)))\n",
    "\n",
    "Result_Dec=clf.predict(X_test)\n",
    "prediction = .0\n",
    "n_test_samples = len(Y_test)\n",
    "print('N test sample {0}'.format(n_test_samples))\n",
    "for number in range(0,n_test_samples):\n",
    "    if(abs(round(Result_Dec[number])-Y_test[number])<=30.0):\n",
    "        prediction += 1.0\n",
    "prediction /= n_test_samples\n",
    "\n",
    "print ('Score for test data from 27 to 50 of neck circum.: {0}'.format(prediction))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
